{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from typing import Dict, Union\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseModel(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for models.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self, X_train: pd.DataFrame, y_train: pd.Series, epochs: int, lr: float) -> None:\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "        \n",
    "        Params:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training target.\n",
    "        epochs (int): Number of training epochs.\n",
    "        lr (float): Learning rate.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Predict using the model.\n",
    "        \n",
    "        Params:\n",
    "        X (pd.DataFrame): Features to predict.\n",
    "\n",
    "        Returns:\n",
    "        pd.Series: Predictions.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def save(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Save the model to a file.\n",
    "        \n",
    "        Params:\n",
    "        path (str): Path to save the model.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Load the model from a file.\n",
    "        \n",
    "        Params:\n",
    "        path (str): Path to load the model.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def evaluate(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluate the model.\n",
    "        \n",
    "        Params:\n",
    "        X (pd.DataFrame): Features to evaluate.\n",
    "        y (pd.Series): True values.\n",
    "\n",
    "        Returns:\n",
    "        Dict[str, float]: Evaluation metrics.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_params(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Get model parameters.\n",
    "        \n",
    "        Returns:\n",
    "        Dict[str, float]: Model parameters.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple MLP model using PyTorch.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.l2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.l3=nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.l4=nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.l5=nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.l6 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.l1(x))\n",
    "        x= torch.relu(self.l2(x))\n",
    "        x= torch.relu(self.l3(x))\n",
    "        x= torch.relu(self.l4(x))\n",
    "        x= torch.relu(self.l5(x))\n",
    "        \n",
    "        x = self.l6(x)\n",
    "        return x\n",
    "\n",
    "class MLPModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Wrapper for the MLP model using PyTorch.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim: int = 23, hidden_dim: int = 128, output_dim: int = 1, id: str = None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the MLPModel.\n",
    "        \n",
    "        Params:\n",
    "        input_dim (int): Number of input features.\n",
    "        hidden_dim (int): Number of hidden units.\n",
    "        output_dim (int): Number of output units.\n",
    "        id (str): Optional model ID to load a saved model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if id is None:\n",
    "            self.model = MLP(input_dim, hidden_dim, output_dim)\n",
    "        else:\n",
    "            self.load(id)\n",
    "        \n",
    "    def train(self, X_train: pd.DataFrame, y_train: pd.Series, epochs: int = 1000, lr: float = 0.001) -> None:\n",
    "        \"\"\"\n",
    "        Train the MLP model.\n",
    "        \n",
    "        Params:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training target.\n",
    "        epochs (int): Number of training epochs.\n",
    "        lr (float): Learning rate.\n",
    "        \"\"\"\n",
    "        self.model_trained = self.model\n",
    "        self.scaler=StandardScaler()\n",
    "        optimizer = optim.Adam(self.model_trained.parameters(), lr=lr)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        \n",
    "        X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        y_train = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "        y_train=self.scaler.fit_transform(y_train.reshape(-1,1))\n",
    "        y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.epoch = epochs\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.model_trained.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self.model_trained(X_train)\n",
    "            loss = loss_fn(y_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (epoch+1) % 100 == 0:\n",
    "                print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "        \n",
    "    def predict(self, X: Union[pd.DataFrame, pd.Series]) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Predict using the MLP model.\n",
    "        \n",
    "        Params:\n",
    "        X (Union[pd.DataFrame, pd.Series]): Features to predict.\n",
    "\n",
    "        Returns:\n",
    "        pd.Series: Predictions.\n",
    "        \"\"\"\n",
    "        self.model_trained.eval()\n",
    "        X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.model_trained(X)\n",
    "        y_pred=self.scaler.inverse_transform(y_pred.numpy())\n",
    "        return pd.Series(y_pred.flatten())\n",
    "    \n",
    "    def save(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Save the MLP model to a file.\n",
    "        \n",
    "        Params:\n",
    "        path (str): Path to save the model.\n",
    "        \"\"\"\n",
    "        torch.save(self.model_trained.state_dict(), path)\n",
    "        \n",
    "    def load(self, path: str) -> None:\n",
    "        \"\"\"\n",
    "        Load the MLP model from a file.\n",
    "        \n",
    "        Params:\n",
    "        path (str): Path to load the model.\n",
    "        \"\"\"\n",
    "        self.model_trained = self.model\n",
    "        self.model_trained.load_state_dict(torch.load(path))\n",
    "        \n",
    "    def evaluate(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluate the MLP model.\n",
    "        \n",
    "        Params:\n",
    "        X (pd.DataFrame): Features to evaluate.\n",
    "        y (pd.Series): True values.\n",
    "\n",
    "        Returns:\n",
    "        Dict[str, float]: Evaluation metrics.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        mse = mean_squared_error(y, y_pred)\n",
    "        self.mae_mse = {\"mae\": mae, \"mse\": mse}\n",
    "        return self.mae_mse\n",
    "    \n",
    "    def get_params(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Get the MLP model parameters.\n",
    "        \n",
    "        Returns:\n",
    "        Dict[str, float]: Model parameters.\n",
    "        \"\"\"\n",
    "        params = {\"hidden_units\": self.model.l1.out_features,\n",
    "                  \"learning_rate\": self.lr, **self.mae_mse}\n",
    "        self.params = params\n",
    "        return params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you have X_train, y_train, X_test, y_test as your data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/diamonds.csv')\n",
    "y=data['price']\n",
    "X=data.drop('price', axis=1)\n",
    "X=pd.get_dummies(X,dtype=float)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 1.0020232200622559\n",
      "Epoch 200, Loss: 0.9988021850585938\n",
      "Epoch 300, Loss: 0.9943796992301941\n",
      "Epoch 400, Loss: 0.9882417917251587\n",
      "Epoch 500, Loss: 0.9773734211921692\n",
      "Epoch 600, Loss: 0.9583086371421814\n",
      "Epoch 700, Loss: 0.9253170490264893\n",
      "Epoch 800, Loss: 0.8745217323303223\n",
      "Epoch 900, Loss: 0.8049335479736328\n",
      "Epoch 1000, Loss: 0.723926305770874\n",
      "Epoch 1100, Loss: 0.6375624537467957\n",
      "Epoch 1200, Loss: 0.5530216693878174\n",
      "Epoch 1300, Loss: 0.474772185087204\n",
      "Epoch 1400, Loss: 0.4055730104446411\n",
      "Epoch 1500, Loss: 0.34668639302253723\n",
      "Epoch 1600, Loss: 0.29940178990364075\n",
      "Epoch 1700, Loss: 0.26314908266067505\n",
      "Epoch 1800, Loss: 0.23565377295017242\n",
      "Epoch 1900, Loss: 0.21485324203968048\n",
      "Epoch 2000, Loss: 0.19888974726200104\n",
      "Epoch 2100, Loss: 0.18617551028728485\n",
      "Epoch 2200, Loss: 0.1755368858575821\n",
      "Epoch 2300, Loss: 0.16624696552753448\n",
      "Epoch 2400, Loss: 0.15776914358139038\n",
      "Epoch 2500, Loss: 0.1500587910413742\n",
      "Epoch 2600, Loss: 0.14308661222457886\n",
      "Epoch 2700, Loss: 0.136713445186615\n",
      "Epoch 2800, Loss: 0.13071899116039276\n",
      "Epoch 2900, Loss: 0.1258370727300644\n",
      "Epoch 3000, Loss: 0.12147323042154312\n",
      "Epoch 3100, Loss: 0.11730299890041351\n",
      "Epoch 3200, Loss: 0.11336706578731537\n",
      "Epoch 3300, Loss: 0.10958217084407806\n",
      "Epoch 3400, Loss: 0.10596223920583725\n",
      "Epoch 3500, Loss: 0.10249020159244537\n",
      "Epoch 3600, Loss: 0.09920242428779602\n",
      "Epoch 3700, Loss: 0.09604545682668686\n",
      "Epoch 3800, Loss: 0.09301872551441193\n",
      "Epoch 3900, Loss: 0.09016259759664536\n",
      "Epoch 4000, Loss: 0.08748115599155426\n",
      "Epoch 4100, Loss: 0.08495310693979263\n",
      "Epoch 4200, Loss: 0.08253557980060577\n",
      "Epoch 4300, Loss: 0.08021531999111176\n",
      "Epoch 4400, Loss: 0.07802197337150574\n",
      "Epoch 4500, Loss: 0.07590983808040619\n",
      "Epoch 4600, Loss: 0.07388521730899811\n",
      "Epoch 4700, Loss: 0.07195471972227097\n",
      "Epoch 4800, Loss: 0.07009819895029068\n",
      "Epoch 4900, Loss: 0.06830401718616486\n",
      "Epoch 5000, Loss: 0.06657644361257553\n"
     ]
    }
   ],
   "source": [
    "model = MLPModel(input_dim=X_train.shape[1], hidden_dim=5, output_dim=1)\n",
    "model.train(X_train, y_train, epochs=5000, lr=0.0001)\n",
    "metrics = model.evaluate(X_test, y_test)\n",
    "model.save('model.pth')\n",
    "params = model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_units': 5,\n",
       " 'learning_rate': 0.0001,\n",
       " 'mae': 714.4256802978516,\n",
       " 'mse': 1032427.3345071009}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
