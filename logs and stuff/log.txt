============================= test session starts ==============================
platform darwin -- Python 3.11.9, pytest-7.4.0, pluggy-1.0.0
rootdir: /Users/carlopiccinin/Desktop/side projects/xtream-ai/xtream-ai-assignment-developer
plugins: anyio-3.5.0, time-machine-2.14.1
collected 39 items

tests/test_MLP_model.py ....FF.                                          [ 17%]
tests/test_base_models.py ...                                            [ 25%]
tests/test_diamond_model.py ....FF...F......                             [ 66%]
tests/test_linear_regression.py ......                                   [ 82%]
tests/test_xgb_regressor_model.py ..F.F..                                [100%]

=================================== FAILURES ===================================
_____________________________ test_mlp_get_params ______________________________

mlp_model = <DiamondModels.MLPModel object at 0x165389110>
sample_data =    feature1  feature2  target
0         1         2       3
1         2         4       6
2         3         6       9
3         4         8      12
4         5        10      15

    def test_mlp_get_params(mlp_model, sample_data):
        X = sample_data[['feature1', 'feature2']]
        y = sample_data['target']
        mlp_model.train(X, y, epochs=10)
>       params = mlp_model.get_params()

tests/test_MLP_model.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <DiamondModels.MLPModel object at 0x165389110>

    def get_params(self) -> Dict[str, float]:
        """
        Get the MLP model parameters.
    
        Returns:
        Dict[str, float]: Model parameters.
        """
>       params = {"hidden_units": self.model.input_layer.out_features,
                  "learning_rate": self.lr, **self.mae_mse}
E       TypeError: 'NoneType' object is not a mapping

DiamondModels.py:359: TypeError
______________________________ test_mlp_save_load ______________________________

mlp_model = <DiamondModels.MLPModel object at 0x1668d8790>
sample_data =    feature1  feature2  target
0         1         2       3
1         2         4       6
2         3         6       9
3         4         8      12
4         5        10      15
tmp_path = PosixPath('/private/var/folders/p8/93vsd8lj4sx0j8xxdgwj_gmr0000gn/T/pytest-of-carlopiccinin/pytest-0/test_mlp_save_load0')

    def test_mlp_save_load(mlp_model, sample_data, tmp_path):
        X = sample_data[['feature1', 'feature2']]
        y = sample_data['target']
        mlp_model.train(X, y, epochs=10)
    
        save_path = tmp_path / "mlp_model.pkl"
        mlp_model.save(str(save_path))
    
        loaded_model = MLPModel(input_dim=2)
>       loaded_model.load(str(save_path))

tests/test_MLP_model.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
DiamondModels.py:330: in load
    self.model.load_state_dict(torch.load(path))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = MLP(
  (input_layer): Linear(in_features=19, out_features=128, bias=True)
  (hidden_layers): ModuleList(
    (0-4): 5 ...n_features=128, out_features=128, bias=True)
  )
  (output_layer): Linear(in_features=128, out_features=1, bias=True)
)
state_dict = OrderedDict([('input_layer.weight', tensor([[-0.3510, -0.5083],
        [-0.5410,  0.2597],
        [-0.1203,  0.5730]...   0.0437,  0.0297,  0.0697,  0.0227,  0.0298,  0.0712,  0.0876, -0.0105]])), ('output_layer.bias', tensor([0.0284]))])
strict = True, assign = False

    def load_state_dict(self, state_dict: Mapping[str, Any],
                        strict: bool = True, assign: bool = False):
        r"""Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.
    
        If :attr:`strict` is ``True``, then
        the keys of :attr:`state_dict` must exactly match the keys returned
        by this module's :meth:`~torch.nn.Module.state_dict` function.
    
        .. warning::
            If :attr:`assign` is ``True`` the optimizer must be created after
            the call to :attr:`load_state_dict` unless
            :func:`~torch.__future__.get_swap_module_params_on_conversion` is ``True``.
    
        Args:
            state_dict (dict): a dict containing parameters and
                persistent buffers.
            strict (bool, optional): whether to strictly enforce that the keys
                in :attr:`state_dict` match the keys returned by this module's
                :meth:`~torch.nn.Module.state_dict` function. Default: ``True``
            assign (bool, optional): When ``False``, the properties of the tensors
                in the current module are preserved while when ``True``, the
                properties of the Tensors in the state dict are preserved. The only
                exception is the ``requires_grad`` field of :class:`~torch.nn.Parameter`s
                for which the value from the module is preserved.
                Default: ``False``
    
        Returns:
            ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:
                * **missing_keys** is a list of str containing the missing keys
                * **unexpected_keys** is a list of str containing the unexpected keys
    
        Note:
            If a parameter or buffer is registered as ``None`` and its corresponding key
            exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a
            ``RuntimeError``.
        """
        if not isinstance(state_dict, Mapping):
            raise TypeError(f"Expected state_dict to be dict-like, got {type(state_dict)}.")
    
        missing_keys: List[str] = []
        unexpected_keys: List[str] = []
        error_msgs: List[str] = []
    
        # copy state_dict so _load_from_state_dict can modify it
        metadata = getattr(state_dict, '_metadata', None)
        state_dict = OrderedDict(state_dict)
        if metadata is not None:
            # mypy isn't aware that "_metadata" exists in state_dict
            state_dict._metadata = metadata  # type: ignore[attr-defined]
    
        def load(module, local_state_dict, prefix=''):
            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})
            if assign:
                local_metadata['assign_to_params_buffers'] = assign
            module._load_from_state_dict(
                local_state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)
            for name, child in module._modules.items():
                if child is not None:
                    child_prefix = prefix + name + '.'
                    child_state_dict = {k: v for k, v in local_state_dict.items() if k.startswith(child_prefix)}
                    load(child, child_state_dict, child_prefix)  # noqa: F821
    
            # Note that the hook can modify missing_keys and unexpected_keys.
            incompatible_keys = _IncompatibleKeys(missing_keys, unexpected_keys)
            for hook in module._load_state_dict_post_hooks.values():
                out = hook(module, incompatible_keys)
                assert out is None, (
                    "Hooks registered with ``register_load_state_dict_post_hook`` are not"
                    "expected to return new values, if incompatible_keys need to be modified,"
                    "it should be done inplace."
                )
    
        load(self, state_dict)
        del load
    
        if strict:
            if len(unexpected_keys) > 0:
                error_msgs.insert(
                    0, 'Unexpected key(s) in state_dict: {}. '.format(
                        ', '.join(f'"{k}"' for k in unexpected_keys)))
            if len(missing_keys) > 0:
                error_msgs.insert(
                    0, 'Missing key(s) in state_dict: {}. '.format(
                        ', '.join(f'"{k}"' for k in missing_keys)))
    
        if len(error_msgs) > 0:
>           raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
                               self.__class__.__name__, "\n\t".join(error_msgs)))
E           RuntimeError: Error(s) in loading state_dict for MLP:
E           	size mismatch for input_layer.weight: copying a param with shape torch.Size([128, 2]) from checkpoint, the shape in current model is torch.Size([128, 19]).

../../../../anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:2189: RuntimeError
___________________________ test_get_similar_samples ___________________________

diamond_model = <DiamondModels.DiamondModel object at 0x1681f7950>

    def test_get_similar_samples(diamond_model):
        similar_samples = diamond_model.get_similar_samples(carat=0.23, cut='Ideal', color='E', clarity='SI2', n=2)
        assert isinstance(similar_samples, pd.DataFrame)
>       assert len(similar_samples) == 2
E       assert 1 == 2
E        +  where 1 = len(   carat    cut color clarity  depth  table  price     x     y     z\n0   0.23  Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43)

tests/test_diamond_model.py:66: AssertionError
_______________________ test_prepare_data_for_prediction _______________________

sample_data =    carat      cut color clarity  depth  table  price     x     y     z
0   0.23    Ideal     E     SI2   61.5   55.0  ...I     VS2   62.4   58.0    334  4.20  4.23  2.63
4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75

    def test_prepare_data_for_prediction(sample_data):
        model = DiamondModel(datas=sample_data, model='LinearRegression')
        model.clean_data()
        model.train_model()
    
        new_data = pd.DataFrame({
            'carat': [0.25],
            'cut': ['Ideal'],
            'color': ['E'],
            'clarity': ['VS2']
        })
    
>       prepared_data = DiamondModel.prepare_data_for_prediction(model.datas_dummies, new_data)

tests/test_diamond_model.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

data_blueprint =    carat     x  cut_Ideal  ...  clarity_SI2  clarity_VS1  clarity_VS2
0   0.23  3.95        1.0  ...          1.0     ...0          0.0          1.0
4   0.31  4.34        0.0  ...          1.0          0.0          0.0

[5 rows x 9 columns]
data_to_predict =    carat    cut color clarity
0   0.25  Ideal     E     VS2
target_column = 'price'

    @staticmethod
    def prepare_data_for_prediction(data_blueprint: pd.DataFrame, data_to_predict: pd.DataFrame, target_column: str = "price") -> pd.DataFrame:
        """
        Prepares the data to be predicted by ensuring it has the same columns as the training data.
    
        Params:
        data_blueprint (pd.DataFrame): The dataframe blueprint with the expected columns.
        data_to_predict (pd.DataFrame): The new data to prepare for prediction.
        target_column (str): The target column to exclude from prediction data.
    
        Returns:
        pd.DataFrame: The prepared dataframe with the same columns as the blueprint.
        """
        ## Check if the target column is in the data blueprint
        if target_column in data_blueprint.columns:
            data_blueprint = data_blueprint.drop(columns=[target_column])
        ## Check if the columns are the same,if they are the same, return the data_to_predict
        if list(data_to_predict.columns) == list(data_blueprint.columns):
            return data_to_predict
    
        blueprint_columns = set(col.split('_')[0] for col in data_blueprint.columns)
        data_columns = set(data_to_predict.columns)
        missing_columns = blueprint_columns - data_columns
        if missing_columns:
            print(data_columns)
            print("#"*100)
>           raise ValueError(f"Missing columns in the data you want to predict: {missing_columns}")
E           ValueError: Missing columns in the data you want to predict: {'x'}

DiamondModels.py:648: ValueError
----------------------------- Captured stdout call -----------------------------
{'carat', 'color', 'clarity', 'cut'}
####################################################################################################
__________________________ test_different_models[MLP] __________________________

sample_data =    carat      cut color clarity  depth  table  price     x     y     z
0   0.23    Ideal     E     SI2   61.5   55.0  ...I     VS2   62.4   58.0    334  4.20  4.23  2.63
4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75
model_name = 'MLP'

    @pytest.mark.parametrize("model_name", ["LinearRegression", "XGBRegressor", "MLP"])
    def test_different_models(sample_data, model_name):
        model = DiamondModel(datas=sample_data, model=model_name)
        model.clean_data()
>       mae_mse = model.train_model()

tests/test_diamond_model.py:101: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
DiamondModels.py:827: in train_model
    self.model.train(X_train=X_train, y_train=y_train)
DiamondModels.py:283: in train
    y_pred = self.model_trained(X_train)
../../../../anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../../../../anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541: in _call_impl
    return forward_call(*args, **kwargs)
DiamondModels.py:229: in forward
    x = torch.relu(self.input_layer(x))
../../../../anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../../../../anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541: in _call_impl
    return forward_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Linear(in_features=19, out_features=128, bias=True)
input = tensor([[0.3100, 4.3400, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000],
        [0.2300, 4.0500, 0.0000, 0.0...00, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.2900, 4.2000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000]])

    def forward(self, input: Tensor) -> Tensor:
>       return F.linear(input, self.weight, self.bias)
E       RuntimeError: mat1 and mat2 shapes cannot be multiplied (4x9 and 19x128)

../../../../anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116: RuntimeError
__________________________ test_xgb_regressor_predict __________________________

xgb_model = <DiamondModels.XGBRegressorModel object at 0x1754a5610>
sample_data =    feature1  feature2  target
0         1         2       3
1         2         4       6
2         3         6       9
3         4         8      12
4         5        10      15

    def test_xgb_regressor_predict(xgb_model, sample_data):
        X = sample_data[['feature1', 'feature2']]
        y = sample_data['target']
        xgb_model.train(X, y)
        predictions = xgb_model.predict(X)
        assert len(predictions) == len(y)
>       assert isinstance(predictions, pd.Series)
E       AssertionError: assert False
E        +  where False = isinstance(array([ 4.4995427,  4.4995427,  9.001052 , 13.499931 , 13.499931 ],\n      dtype=float32), <class 'pandas.core.series.Series'>)
E        +    where <class 'pandas.core.series.Series'> = pd.Series

tests/test_xgb_regressor_model.py:33: AssertionError
----------------------------- Captured stderr call -----------------------------
[I 2024-06-30 20:06:56,998] A new study created in memory with name: no-name-588e9db6-5daf-43ed-a9c9-a337e87492a1
[I 2024-06-30 20:06:57,084] Trial 0 finished with value: 3.75 and parameters: {'lambda': 1.368469468093869e-07, 'alpha': 0.5526359848511877, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.7477120523037187, 'n_estimators': 506, 'max_depth': 4, 'min_child_weight': 6}. Best is trial 0 with value: 3.75.
[I 2024-06-30 20:06:57,151] Trial 1 finished with value: 3.7495059967041016 and parameters: {'lambda': 1.8651367738061925e-07, 'alpha': 2.757089003231057e-06, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 8.013926593152583e-07, 'n_estimators': 255, 'max_depth': 3, 'min_child_weight': 2}. Best is trial 1 with value: 3.7495059967041016.
[I 2024-06-30 20:06:57,203] Trial 2 finished with value: 3.75 and parameters: {'lambda': 0.04918408955366978, 'alpha': 2.203446838139434e-08, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 1.3216101213948566e-06, 'n_estimators': 274, 'max_depth': 7, 'min_child_weight': 9}. Best is trial 1 with value: 3.7495059967041016.
[I 2024-06-30 20:06:57,296] Trial 3 finished with value: 3.75 and parameters: {'lambda': 3.413388067258159e-08, 'alpha': 4.293114638506285e-08, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.11884100789805384, 'n_estimators': 568, 'max_depth': 6, 'min_child_weight': 6}. Best is trial 1 with value: 3.7495059967041016.
[I 2024-06-30 20:06:57,397] Trial 4 finished with value: 3.75 and parameters: {'lambda': 0.0781185853765672, 'alpha': 2.7640226989204772e-05, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.005929271755462514, 'n_estimators': 934, 'max_depth': 9, 'min_child_weight': 6}. Best is trial 1 with value: 3.7495059967041016.
[I 2024-06-30 20:06:57,460] Trial 5 finished with value: 3.75 and parameters: {'lambda': 0.00019893841701971117, 'alpha': 0.0005481965019923656, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.03445782693788154, 'n_estimators': 844, 'max_depth': 7, 'min_child_weight': 5}. Best is trial 1 with value: 3.7495059967041016.
[I 2024-06-30 20:06:57,488] Trial 6 finished with value: 3.75 and parameters: {'lambda': 0.025069741206123545, 'alpha': 1.2669043378412997e-05, 'colsample_bytree': 0.4, 'subsample': 0.7, 'learning_rate': 0.16453460645119833, 'n_estimators': 333, 'max_depth': 8, 'min_child_weight': 9}. Best is trial 1 with value: 3.7495059967041016.
[I 2024-06-30 20:06:57,507] Trial 7 finished with value: 3.7601919174194336 and parameters: {'lambda': 7.689560276701134e-05, 'alpha': 0.5505035459356027, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 9.566959178386086e-05, 'n_estimators': 227, 'max_depth': 9, 'min_child_weight': 3}. Best is trial 1 with value: 3.7495059967041016.
[I 2024-06-30 20:06:57,542] Trial 8 finished with value: 3.75 and parameters: {'lambda': 1.4031225597260766e-06, 'alpha': 0.0003889043917199638, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.8439874392900794, 'n_estimators': 383, 'max_depth': 3, 'min_child_weight': 9}. Best is trial 1 with value: 3.7495059967041016.
[I 2024-06-30 20:06:57,609] Trial 9 finished with value: 3.75 and parameters: {'lambda': 7.135753310396993e-05, 'alpha': 0.005115730640204925, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.0060864528066199375, 'n_estimators': 900, 'max_depth': 5, 'min_child_weight': 4}. Best is trial 1 with value: 3.7495059967041016.
[I 2024-06-30 20:06:57,698] Trial 10 finished with value: 3.75 and parameters: {'lambda': 2.637257667060049e-06, 'alpha': 3.3147561248057258e-06, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 1.1521264948676905e-08, 'n_estimators': 143, 'max_depth': 3, 'min_child_weight': 1}. Best is trial 1 with value: 3.7495059967041016.
[I 2024-06-30 20:06:57,774] Trial 11 finished with value: 3.725592613220215 and parameters: {'lambda': 1.283984623013074e-08, 'alpha': 0.8203037896727062, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 9.165173352275815e-06, 'n_estimators': 515, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 11 with value: 3.725592613220215.
[I 2024-06-30 20:06:58,076] Trial 12 finished with value: 3.738069534301758 and parameters: {'lambda': 1.0739094031971566e-08, 'alpha': 6.352247005461214e-07, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 2.959762584252646e-06, 'n_estimators': 669, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 11 with value: 3.725592613220215.
[I 2024-06-30 20:06:58,397] Trial 13 finished with value: 3.6364402770996094 and parameters: {'lambda': 1.1995216775467844e-08, 'alpha': 2.282861365955779e-07, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 3.158450579428332e-05, 'n_estimators': 667, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 13 with value: 3.6364402770996094.
[I 2024-06-30 20:06:58,463] Trial 14 finished with value: 3.762451171875 and parameters: {'lambda': 3.006915252107667e-06, 'alpha': 0.03626356996569626, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 6.521462233839489e-05, 'n_estimators': 743, 'max_depth': 5, 'min_child_weight': 3}. Best is trial 13 with value: 3.6364402770996094.
[I 2024-06-30 20:06:58,545] Trial 15 finished with value: 3.700375556945801 and parameters: {'lambda': 1.0562854348167227e-08, 'alpha': 2.1441533110544773e-07, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 1.7047343501295026e-05, 'n_estimators': 540, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 13 with value: 3.6364402770996094.
[I 2024-06-30 20:06:58,601] Trial 16 finished with value: 3.860322952270508 and parameters: {'lambda': 0.0012182916900031625, 'alpha': 1.8203156296754384e-07, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.0008061393303564158, 'n_estimators': 652, 'max_depth': 6, 'min_child_weight': 3}. Best is trial 13 with value: 3.6364402770996094.
[I 2024-06-30 20:06:58,649] Trial 17 finished with value: 3.75 and parameters: {'lambda': 3.2081961421105246e-07, 'alpha': 2.633336795007469e-07, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 3.230931584100818e-08, 'n_estimators': 423, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 13 with value: 3.6364402770996094.
[I 2024-06-30 20:06:58,721] Trial 18 finished with value: 3.75 and parameters: {'lambda': 1.2894926648608822e-05, 'alpha': 1.1441168646816317e-08, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 1.4987662702957067e-07, 'n_estimators': 780, 'max_depth': 7, 'min_child_weight': 4}. Best is trial 13 with value: 3.6364402770996094.
[I 2024-06-30 20:06:58,775] Trial 19 finished with value: 3.75 and parameters: {'lambda': 0.004154160725900902, 'alpha': 1.5698460178260445e-06, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 1.4959096106647287e-05, 'n_estimators': 624, 'max_depth': 5, 'min_child_weight': 7}. Best is trial 13 with value: 3.6364402770996094.
[I 2024-06-30 20:06:58,846] Trial 20 finished with value: 3.1022586822509766 and parameters: {'lambda': 8.170263132053247e-08, 'alpha': 6.899960388657309e-08, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.00131578183708009, 'n_estimators': 778, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 20 with value: 3.1022586822509766.
[I 2024-06-30 20:06:58,926] Trial 21 finished with value: 3.457402229309082 and parameters: {'lambda': 0.6433302677662547, 'alpha': 6.27152563464286e-08, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.0009008056806766951, 'n_estimators': 744, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 20 with value: 3.1022586822509766.
[I 2024-06-30 20:06:58,999] Trial 22 finished with value: 3.6115942001342773 and parameters: {'lambda': 0.3440896341425517, 'alpha': 6.508474594901986e-08, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.00039615760095870387, 'n_estimators': 745, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 20 with value: 3.1022586822509766.
[I 2024-06-30 20:06:59,093] Trial 23 finished with value: 3.527528762817383 and parameters: {'lambda': 0.8147399963656825, 'alpha': 5.174406887091365e-08, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.0005439109299760319, 'n_estimators': 998, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 20 with value: 3.1022586822509766.
[I 2024-06-30 20:06:59,172] Trial 24 finished with value: 3.75 and parameters: {'lambda': 0.9011517874395141, 'alpha': 1.0328286399877316e-08, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.0014296446084075556, 'n_estimators': 874, 'max_depth': 7, 'min_child_weight': 4}. Best is trial 20 with value: 3.1022586822509766.
[I 2024-06-30 20:06:59,270] Trial 25 finished with value: 3.5557708740234375 and parameters: {'lambda': 0.008491824467888051, 'alpha': 1.4399007785710586e-05, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.00032792741151527183, 'n_estimators': 996, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 20 with value: 3.1022586822509766.
[I 2024-06-30 20:06:59,338] Trial 26 finished with value: 4.1091814041137695 and parameters: {'lambda': 0.3026129821792581, 'alpha': 7.006818224367368e-08, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.004007427228343219, 'n_estimators': 807, 'max_depth': 8, 'min_child_weight': 3}. Best is trial 20 with value: 3.1022586822509766.
[I 2024-06-30 20:06:59,426] Trial 27 finished with value: 3.75 and parameters: {'lambda': 0.000746604140602855, 'alpha': 8.429213622381397e-07, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.020351748021632823, 'n_estimators': 999, 'max_depth': 6, 'min_child_weight': 4}. Best is trial 20 with value: 3.1022586822509766.
[I 2024-06-30 20:06:59,503] Trial 28 finished with value: 3.75 and parameters: {'lambda': 0.12953901628601897, 'alpha': 6.075015411858361e-08, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.00019464027763738167, 'n_estimators': 952, 'max_depth': 8, 'min_child_weight': 5}. Best is trial 20 with value: 3.1022586822509766.
[I 2024-06-30 20:06:59,579] Trial 29 finished with value: 3.75 and parameters: {'lambda': 0.8785328427505146, 'alpha': 8.701649923692298e-05, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.001874308630431437, 'n_estimators': 753, 'max_depth': 7, 'min_child_weight': 7}. Best is trial 20 with value: 3.1022586822509766.
[I 2024-06-30 20:06:59,661] Trial 30 finished with value: 0.8843517303466797 and parameters: {'lambda': 0.01792851077968198, 'alpha': 6.136368263585593e-07, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.021958829319737055, 'n_estimators': 858, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 30 with value: 0.8843517303466797.
[I 2024-06-30 20:06:59,834] Trial 31 finished with value: 0.8707852363586426 and parameters: {'lambda': 0.01341325145075626, 'alpha': 4.3223135207573055e-07, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.025492681007773896, 'n_estimators': 840, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 31 with value: 0.8707852363586426.
[I 2024-06-30 20:06:59,914] Trial 32 finished with value: 0.8271408081054688 and parameters: {'lambda': 0.013039164058591887, 'alpha': 3.579108471289584e-06, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.0246381568548842, 'n_estimators': 830, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:06:59,987] Trial 33 finished with value: 4.795733451843262 and parameters: {'lambda': 0.013101301518422247, 'alpha': 6.982403899568269e-06, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.16707861582341058, 'n_estimators': 828, 'max_depth': 4, 'min_child_weight': 3}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:00,151] Trial 34 finished with value: 0.8542003631591797 and parameters: {'lambda': 0.0014541957639722344, 'alpha': 2.022735687626719e-06, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.020595696394668975, 'n_estimators': 892, 'max_depth': 3, 'min_child_weight': 2}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:00,225] Trial 35 finished with value: 3.75 and parameters: {'lambda': 0.0035590730579832747, 'alpha': 3.3598064355694185e-06, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.034594431548206996, 'n_estimators': 895, 'max_depth': 3, 'min_child_weight': 3}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:00,358] Trial 36 finished with value: 2.9970242977142334 and parameters: {'lambda': 0.0009001607218934328, 'alpha': 6.141712458205162e-05, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.014062859390246884, 'n_estimators': 935, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:00,426] Trial 37 finished with value: 3.75 and parameters: {'lambda': 0.037903575632011674, 'alpha': 8.422447511453674e-07, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.0834640489228926, 'n_estimators': 841, 'max_depth': 3, 'min_child_weight': 5}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:00,492] Trial 38 finished with value: 3.75 and parameters: {'lambda': 0.0002504053563296491, 'alpha': 3.0405062613093605e-05, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.432464966650948, 'n_estimators': 708, 'max_depth': 4, 'min_child_weight': 10}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:00,578] Trial 39 finished with value: 1.106553077697754 and parameters: {'lambda': 0.09379890537971838, 'alpha': 0.00022835718130953945, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.07174636499090874, 'n_estimators': 874, 'max_depth': 3, 'min_child_weight': 2}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:00,636] Trial 40 finished with value: 3.75 and parameters: {'lambda': 0.015548334201149781, 'alpha': 7.689248425351674e-06, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.34035597090843034, 'n_estimators': 580, 'max_depth': 4, 'min_child_weight': 3}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:00,718] Trial 41 finished with value: 1.0533499717712402 and parameters: {'lambda': 0.08327176910017695, 'alpha': 0.0007718548006968822, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.08934164689621242, 'n_estimators': 880, 'max_depth': 3, 'min_child_weight': 2}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:00,844] Trial 42 finished with value: 2.9883718490600586 and parameters: {'lambda': 0.0023296995030449856, 'alpha': 0.0021154822283307073, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.012043232792039895, 'n_estimators': 925, 'max_depth': 3, 'min_child_weight': 1}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:00,921] Trial 43 finished with value: 1.011385440826416 and parameters: {'lambda': 0.03902452412770513, 'alpha': 0.0012029217444850641, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.040780563132423626, 'n_estimators': 814, 'max_depth': 3, 'min_child_weight': 2}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:00,996] Trial 44 finished with value: 3.75 and parameters: {'lambda': 0.028586898224337715, 'alpha': 0.012655061841877589, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.006202047269220741, 'n_estimators': 812, 'max_depth': 4, 'min_child_weight': 4}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:01,085] Trial 45 finished with value: 3.830948829650879 and parameters: {'lambda': 0.00949900617378062, 'alpha': 1.3549554997116766e-06, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.03701998900237356, 'n_estimators': 946, 'max_depth': 3, 'min_child_weight': 3}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:01,160] Trial 46 finished with value: 2.5992298126220703 and parameters: {'lambda': 0.0003705948441508501, 'alpha': 3.6519609417469296e-07, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.0036933377240735417, 'n_estimators': 854, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:01,225] Trial 47 finished with value: 2.824511766433716 and parameters: {'lambda': 0.005224404631005583, 'alpha': 0.1759483582782823, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.27976735443255635, 'n_estimators': 702, 'max_depth': 3, 'min_child_weight': 1}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:01,301] Trial 48 finished with value: 2.9977636337280273 and parameters: {'lambda': 0.0019479593170134467, 'alpha': 0.0019063647573051502, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.8408255483139361, 'n_estimators': 804, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:01,341] Trial 49 finished with value: 3.75 and parameters: {'lambda': 3.924076460836068e-05, 'alpha': 2.8815186346994153e-06, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.011996384145252762, 'n_estimators': 463, 'max_depth': 4, 'min_child_weight': 7}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:01,402] Trial 50 finished with value: 1.0739727020263672 and parameters: {'lambda': 0.03754716019920929, 'alpha': 3.25757376356701e-05, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.044114414308218976, 'n_estimators': 603, 'max_depth': 3, 'min_child_weight': 2}. Best is trial 32 with value: 0.8271408081054688.
[I 2024-06-30 20:07:01,486] Trial 51 finished with value: 0.4999117851257324 and parameters: {'lambda': 0.16301985350799772, 'alpha': 0.0006258165952519873, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.1515414042503635, 'n_estimators': 889, 'max_depth': 3, 'min_child_weight': 2}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:01,570] Trial 52 finished with value: 4.152091026306152 and parameters: {'lambda': 0.2130171530203642, 'alpha': 0.00022908295549807728, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.1746918543120415, 'n_estimators': 903, 'max_depth': 3, 'min_child_weight': 3}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:01,666] Trial 53 finished with value: 0.8879151344299316 and parameters: {'lambda': 0.05316568471009985, 'alpha': 0.0012296180463431594, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.019677534576538508, 'n_estimators': 958, 'max_depth': 3, 'min_child_weight': 2}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:01,924] Trial 54 finished with value: 2.929783582687378 and parameters: {'lambda': 0.019512703840283703, 'alpha': 0.011272614882016795, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.008390281920202637, 'n_estimators': 966, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:01,996] Trial 55 finished with value: 4.149640083312988 and parameters: {'lambda': 0.06290625702491047, 'alpha': 0.00020437013895484058, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.0037996299515027448, 'n_estimators': 905, 'max_depth': 4, 'min_child_weight': 3}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,081] Trial 56 finished with value: 0.9145708084106445 and parameters: {'lambda': 0.14227370371674947, 'alpha': 1.351104968123252e-07, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.020258009834270476, 'n_estimators': 857, 'max_depth': 3, 'min_child_weight': 2}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,119] Trial 57 finished with value: 3.75 and parameters: {'lambda': 0.00524639635414281, 'alpha': 5.567953787676382e-07, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.0023088439425028064, 'n_estimators': 286, 'max_depth': 5, 'min_child_weight': 4}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,204] Trial 58 finished with value: 2.994047164916992 and parameters: {'lambda': 0.007122580042157868, 'alpha': 0.00559534719228832, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.4459277454027257, 'n_estimators': 963, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,282] Trial 59 finished with value: 3.75 and parameters: {'lambda': 0.001901252250362439, 'alpha': 6.667092578536283e-06, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 0.02287239360332073, 'n_estimators': 921, 'max_depth': 3, 'min_child_weight': 8}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,308] Trial 60 finished with value: 1.1693625450134277 and parameters: {'lambda': 0.3144606665564592, 'alpha': 1.754275298844617e-06, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.14118265258265406, 'n_estimators': 117, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,411] Trial 61 finished with value: 1.0256938934326172 and parameters: {'lambda': 0.18928830083424694, 'alpha': 1.437288593382623e-07, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.06198249593807699, 'n_estimators': 851, 'max_depth': 3, 'min_child_weight': 2}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,478] Trial 62 finished with value: 4.101291656494141 and parameters: {'lambda': 0.12407239284393619, 'alpha': 2.8021996895883878e-08, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.013358341048369646, 'n_estimators': 788, 'max_depth': 3, 'min_child_weight': 3}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,562] Trial 63 finished with value: 0.8465871810913086 and parameters: {'lambda': 0.0212213708694026, 'alpha': 1.3451252116132652e-07, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.02699804823850625, 'n_estimators': 861, 'max_depth': 3, 'min_child_weight': 2}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,715] Trial 64 finished with value: 3.7478561401367188 and parameters: {'lambda': 0.0200731441102694, 'alpha': 4.2788895172429e-07, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 5.843792628348375e-07, 'n_estimators': 970, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,791] Trial 65 finished with value: 0.8023676872253418 and parameters: {'lambda': 0.058391841199827134, 'alpha': 0.0005649870685763076, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.007338667299317233, 'n_estimators': 713, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,856] Trial 66 finished with value: 4.1836442947387695 and parameters: {'lambda': 0.013816163132173922, 'alpha': 2.535702233071171e-08, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.24439615601758277, 'n_estimators': 709, 'max_depth': 5, 'min_child_weight': 3}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:02,935] Trial 67 finished with value: 0.7554774284362793 and parameters: {'lambda': 0.00045103171764398857, 'alpha': 0.0004658390140543729, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.007331297547442549, 'n_estimators': 753, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:03,046] Trial 68 finished with value: 2.7220146656036377 and parameters: {'lambda': 0.0005132919319893632, 'alpha': 0.0004573878888420623, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.00707863443317203, 'n_estimators': 640, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:03,130] Trial 69 finished with value: 1.68699312210083 and parameters: {'lambda': 0.003384087795070352, 'alpha': 0.0001012100597570669, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.0030215552797953943, 'n_estimators': 767, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:03,190] Trial 70 finished with value: 3.75 and parameters: {'lambda': 8.03047657527604e-05, 'alpha': 5.298661227185775e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.0009367721248940269, 'n_estimators': 679, 'max_depth': 5, 'min_child_weight': 4}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:03,274] Trial 71 finished with value: 0.7694520950317383 and parameters: {'lambda': 0.001054124453453875, 'alpha': 1.6381113264845198e-06, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.06928897869851765, 'n_estimators': 833, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 51 with value: 0.4999117851257324.
[I 2024-06-30 20:07:03,343] Trial 72 finished with value: 0.4875030517578125 and parameters: {'lambda': 0.00016244732786598127, 'alpha': 1.2693149271788393e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.05314372441613287, 'n_estimators': 731, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 72 with value: 0.4875030517578125.
[I 2024-06-30 20:07:03,411] Trial 73 finished with value: 4.354377746582031 and parameters: {'lambda': 0.00015199720402610684, 'alpha': 4.3025277787814545e-06, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.12116886906502157, 'n_estimators': 737, 'max_depth': 5, 'min_child_weight': 3}. Best is trial 72 with value: 0.4875030517578125.
[I 2024-06-30 20:07:03,482] Trial 74 finished with value: 0.41284894943237305 and parameters: {'lambda': 2.4077147000432833e-05, 'alpha': 1.5309991451688288e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.07853173735513529, 'n_estimators': 722, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 74 with value: 0.41284894943237305.
[I 2024-06-30 20:07:03,560] Trial 75 finished with value: 2.9992146492004395 and parameters: {'lambda': 3.342350066724629e-05, 'alpha': 0.00013598999361474987, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.10602768607248057, 'n_estimators': 724, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 74 with value: 0.41284894943237305.
[I 2024-06-30 20:07:03,630] Trial 76 finished with value: 0.5803260803222656 and parameters: {'lambda': 4.589194868701029e-06, 'alpha': 1.5109652324202642e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.059420373226677446, 'n_estimators': 677, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 74 with value: 0.41284894943237305.
[I 2024-06-30 20:07:03,695] Trial 77 finished with value: 4.251011848449707 and parameters: {'lambda': 8.473691375556262e-06, 'alpha': 1.0326612556210883e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.06915476151504169, 'n_estimators': 685, 'max_depth': 5, 'min_child_weight': 3}. Best is trial 74 with value: 0.41284894943237305.
[I 2024-06-30 20:07:03,757] Trial 78 finished with value: 3.75 and parameters: {'lambda': 1.11873378501611e-06, 'alpha': 1.8953892442440487e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.6876799482468633, 'n_estimators': 623, 'max_depth': 4, 'min_child_weight': 6}. Best is trial 74 with value: 0.41284894943237305.
[I 2024-06-30 20:07:03,854] Trial 79 finished with value: 0.49555206298828125 and parameters: {'lambda': 8.223599294399017e-06, 'alpha': 1.6995986364152552e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.2126731313874173, 'n_estimators': 648, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 74 with value: 0.41284894943237305.
[I 2024-06-30 20:07:03,908] Trial 80 finished with value: 2.9992828369140625 and parameters: {'lambda': 7.3794867656642445e-06, 'alpha': 4.003574176046563e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.20386545934472514, 'n_estimators': 528, 'max_depth': 6, 'min_child_weight': 1}. Best is trial 74 with value: 0.41284894943237305.
[I 2024-06-30 20:07:03,987] Trial 81 finished with value: 0.42479515075683594 and parameters: {'lambda': 1.89615289115106e-05, 'alpha': 2.3646900711325878e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.5257231335892997, 'n_estimators': 759, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 74 with value: 0.41284894943237305.
[I 2024-06-30 20:07:04,056] Trial 82 finished with value: 0.30464649200439453 and parameters: {'lambda': 2.158451110563283e-05, 'alpha': 1.8675996352979965e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.5409767567064476, 'n_estimators': 656, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 82 with value: 0.30464649200439453.
[I 2024-06-30 20:07:04,127] Trial 83 finished with value: 0.05893135070800781 and parameters: {'lambda': 2.7813191518930837e-05, 'alpha': 2.0188470400821703e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.5562928903723364, 'n_estimators': 658, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,188] Trial 84 finished with value: 3.7146148681640625 and parameters: {'lambda': 2.5410428931603607e-05, 'alpha': 1.7245656359133296e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.5475617817156294, 'n_estimators': 571, 'max_depth': 4, 'min_child_weight': 3}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,250] Trial 85 finished with value: 0.9763126373291016 and parameters: {'lambda': 3.6076757298824484e-06, 'alpha': 2.419580413751415e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.976247890915581, 'n_estimators': 646, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,308] Trial 86 finished with value: 2.9993295669555664 and parameters: {'lambda': 1.8296662611822503e-05, 'alpha': 1.0005020636848138e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.3313570759387213, 'n_estimators': 597, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,372] Trial 87 finished with value: 3.3373947143554688 and parameters: {'lambda': 4.7407015958983235e-05, 'alpha': 4.681167332605945e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.4983997613463886, 'n_estimators': 674, 'max_depth': 9, 'min_child_weight': 3}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,437] Trial 88 finished with value: 0.32525634765625 and parameters: {'lambda': 1.0108227144081622e-06, 'alpha': 0.0001087265909319559, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.23536870370557955, 'n_estimators': 758, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,499] Trial 89 finished with value: 0.5761651992797852 and parameters: {'lambda': 6.648400463780038e-07, 'alpha': 5.613801558669255e-06, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.2207986656376847, 'n_estimators': 550, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,556] Trial 90 finished with value: 2.999509811401367 and parameters: {'lambda': 8.810322744386516e-07, 'alpha': 5.776776849545174e-06, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.2550345796849588, 'n_estimators': 540, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,618] Trial 91 finished with value: 0.6124844551086426 and parameters: {'lambda': 2.789326811108829e-07, 'alpha': 7.810839326695503e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.18203923690043183, 'n_estimators': 623, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,680] Trial 92 finished with value: 0.6717123985290527 and parameters: {'lambda': 4.521440885399216e-06, 'alpha': 2.09182187218195e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.6265470797429139, 'n_estimators': 664, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,751] Trial 93 finished with value: 0.23113346099853516 and parameters: {'lambda': 1.740922995957108e-06, 'alpha': 1.4158133732837833e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.2978896001596194, 'n_estimators': 691, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,807] Trial 94 finished with value: 3.910938262939453 and parameters: {'lambda': 6.844044720227684e-07, 'alpha': 4.8463116324045255e-06, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.3635433382389462, 'n_estimators': 554, 'max_depth': 4, 'min_child_weight': 3}. Best is trial 83 with value: 0.05893135070800781.
[I 2024-06-30 20:07:04,859] Trial 95 finished with value: 7.009506225585938e-05 and parameters: {'lambda': 1.696792912170462e-06, 'alpha': 0.00012207107644874248, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.986660234755642, 'n_estimators': 478, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 95 with value: 7.009506225585938e-05.
[I 2024-06-30 20:07:04,911] Trial 96 finished with value: 0.000362396240234375 and parameters: {'lambda': 1.9831312469225296e-06, 'alpha': 7.013749338525242e-05, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.7368876336372445, 'n_estimators': 496, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 95 with value: 7.009506225585938e-05.
[I 2024-06-30 20:07:04,957] Trial 97 finished with value: 2.999196767807007 and parameters: {'lambda': 1.947938677429076e-06, 'alpha': 0.000144683793256952, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.8422931041238698, 'n_estimators': 421, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 95 with value: 7.009506225585938e-05.
[I 2024-06-30 20:07:05,010] Trial 98 finished with value: 3.75 and parameters: {'lambda': 8.77776607281919e-06, 'alpha': 3.199663909725895e-05, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.9915419571480865, 'n_estimators': 467, 'max_depth': 4, 'min_child_weight': 3}. Best is trial 95 with value: 7.009506225585938e-05.
[I 2024-06-30 20:07:05,060] Trial 99 finished with value: 0.0004830360412597656 and parameters: {'lambda': 6.906512479768481e-08, 'alpha': 6.646671122136418e-05, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.3944311903549758, 'n_estimators': 464, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 95 with value: 7.009506225585938e-05.
________________________ test_xgb_regressor_get_params _________________________

xgb_model = <DiamondModels.XGBRegressorModel object at 0x17507c190>
sample_data =    feature1  feature2  target
0         1         2       3
1         2         4       6
2         3         6       9
3         4         8      12
4         5        10      15

    def test_xgb_regressor_get_params(xgb_model, sample_data):
        X = sample_data[['feature1', 'feature2']]
        y = sample_data['target']
        xgb_model.train(X, y)
>       params = xgb_model.get_params()

tests/test_xgb_regressor_model.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <DiamondModels.XGBRegressorModel object at 0x17507c190>

    def get_params(self) -> Dict[str, float]:
        """
        Get the XGBRegressor model parameters.
    
        Returns:
        Dict[str, float]: Model parameters.
        """
        if hasattr(self, 'best_params'):
>           params = {**self.best_params, 'n_estimators': self.model_trained.n_estimators, **self.mae_mse}
E           AttributeError: 'XGBRegressorModel' object has no attribute 'mae_mse'

DiamondModels.py:449: AttributeError
----------------------------- Captured stderr call -----------------------------
[I 2024-06-30 20:07:15,171] A new study created in memory with name: no-name-e9f80828-59ed-4da5-ab4f-d998326b4d0b
[I 2024-06-30 20:07:15,241] Trial 0 finished with value: 3.738567352294922 and parameters: {'lambda': 0.029597776838842668, 'alpha': 2.6222921705663464e-07, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 7.767102436284078e-06, 'n_estimators': 738, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,268] Trial 1 finished with value: 3.75 and parameters: {'lambda': 0.0021101951637206426, 'alpha': 0.03950596585564746, 'colsample_bytree': 0.7, 'subsample': 0.9, 'learning_rate': 0.0014859815814732777, 'n_estimators': 392, 'max_depth': 3, 'min_child_weight': 5}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,301] Trial 2 finished with value: 3.75 and parameters: {'lambda': 0.008398767184893524, 'alpha': 2.1540042945896473e-06, 'colsample_bytree': 0.4, 'subsample': 0.8, 'learning_rate': 5.181922896150852e-05, 'n_estimators': 422, 'max_depth': 9, 'min_child_weight': 7}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,332] Trial 3 finished with value: 3.75 and parameters: {'lambda': 1.6408844450771692e-08, 'alpha': 5.568550349681934e-06, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 1.9435868170914944e-08, 'n_estimators': 371, 'max_depth': 4, 'min_child_weight': 6}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,345] Trial 4 finished with value: 3.75 and parameters: {'lambda': 1.424541568998758e-06, 'alpha': 5.392651459198585e-05, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 1.598208007883524e-05, 'n_estimators': 160, 'max_depth': 3, 'min_child_weight': 6}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,378] Trial 5 finished with value: 3.75 and parameters: {'lambda': 1.6167880464479184e-06, 'alpha': 0.06883571556922947, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.015479521877394981, 'n_estimators': 419, 'max_depth': 4, 'min_child_weight': 10}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,411] Trial 6 finished with value: 3.75 and parameters: {'lambda': 9.318019469189524e-07, 'alpha': 5.1893277613147313e-05, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.3002606224188961, 'n_estimators': 486, 'max_depth': 5, 'min_child_weight': 6}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,504] Trial 7 finished with value: 3.75 and parameters: {'lambda': 0.0017751389422107956, 'alpha': 0.23662419101435977, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 7.357883645641853e-08, 'n_estimators': 879, 'max_depth': 5, 'min_child_weight': 6}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,584] Trial 8 finished with value: 3.75 and parameters: {'lambda': 9.796030064136246e-05, 'alpha': 1.0988109377436547e-05, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.06600445197711853, 'n_estimators': 977, 'max_depth': 5, 'min_child_weight': 7}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,625] Trial 9 finished with value: 3.75 and parameters: {'lambda': 1.3249678003625815e-05, 'alpha': 2.101768442321076e-05, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 1.3694934289636795e-07, 'n_estimators': 497, 'max_depth': 5, 'min_child_weight': 9}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,749] Trial 10 finished with value: 3.7418479919433594 and parameters: {'lambda': 0.27280788723036203, 'alpha': 1.865642486806273e-08, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 2.5871543913930134e-06, 'n_estimators': 746, 'max_depth': 8, 'min_child_weight': 1}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,852] Trial 11 finished with value: 3.7454280853271484 and parameters: {'lambda': 0.7867543235105114, 'alpha': 1.7315323629275342e-08, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 1.9096009525507793e-06, 'n_estimators': 734, 'max_depth': 8, 'min_child_weight': 1}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:15,970] Trial 12 finished with value: 3.745551109313965 and parameters: {'lambda': 0.1762424643365527, 'alpha': 1.0307890124810652e-08, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 1.2753489575922377e-06, 'n_estimators': 717, 'max_depth': 7, 'min_child_weight': 1}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:16,032] Trial 13 finished with value: 3.7904815673828125 and parameters: {'lambda': 0.06339092619047385, 'alpha': 1.2821085814453553e-07, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.0002323732208766666, 'n_estimators': 695, 'max_depth': 7, 'min_child_weight': 3}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:16,086] Trial 14 finished with value: 3.75 and parameters: {'lambda': 0.022712516969280613, 'alpha': 3.3712988201754083e-07, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 3.0986019807292715e-06, 'n_estimators': 628, 'max_depth': 7, 'min_child_weight': 3}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:16,247] Trial 15 finished with value: 3.7749805450439453 and parameters: {'lambda': 0.8064564317488861, 'alpha': 0.0014068904393149697, 'colsample_bytree': 0.4, 'subsample': 0.9, 'learning_rate': 0.00024075399226278086, 'n_estimators': 836, 'max_depth': 9, 'min_child_weight': 3}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:16,333] Trial 16 finished with value: 3.7494983673095703 and parameters: {'lambda': 0.0005149728910818308, 'alpha': 2.3199465695650722e-07, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 5.565502286791536e-07, 'n_estimators': 828, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:16,396] Trial 17 finished with value: 3.75 and parameters: {'lambda': 0.08493121965048893, 'alpha': 0.0008421971047165771, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 1.0643951128720449e-05, 'n_estimators': 600, 'max_depth': 8, 'min_child_weight': 4}. Best is trial 0 with value: 3.738567352294922.
[I 2024-06-30 20:07:16,547] Trial 18 finished with value: 2.9665451049804688 and parameters: {'lambda': 0.01228602293695315, 'alpha': 8.933504707048624e-07, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.0069915093330998905, 'n_estimators': 960, 'max_depth': 6, 'min_child_weight': 1}. Best is trial 18 with value: 2.9665451049804688.
[I 2024-06-30 20:07:16,652] Trial 19 finished with value: 0.5588512420654297 and parameters: {'lambda': 0.000126361403149706, 'alpha': 9.848032015084105e-07, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.004566127818584629, 'n_estimators': 999, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 19 with value: 0.5588512420654297.
[I 2024-06-30 20:07:16,739] Trial 20 finished with value: 3.75 and parameters: {'lambda': 6.320023323931785e-05, 'alpha': 1.381152707845652e-06, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.004678345078786443, 'n_estimators': 957, 'max_depth': 6, 'min_child_weight': 4}. Best is trial 19 with value: 0.5588512420654297.
[I 2024-06-30 20:07:16,836] Trial 21 finished with value: 2.065073013305664 and parameters: {'lambda': 0.004267873972631814, 'alpha': 6.155253797484976e-07, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.0012641886500148868, 'n_estimators': 917, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 19 with value: 0.5588512420654297.
[I 2024-06-30 20:07:16,932] Trial 22 finished with value: 2.1864051818847656 and parameters: {'lambda': 0.0012430131248242528, 'alpha': 0.0006230516073709362, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.0011552211844286554, 'n_estimators': 899, 'max_depth': 7, 'min_child_weight': 2}. Best is trial 19 with value: 0.5588512420654297.
[I 2024-06-30 20:07:17,028] Trial 23 finished with value: 2.2361249923706055 and parameters: {'lambda': 0.0004911440027580541, 'alpha': 0.00023720827558128797, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.001116900640310134, 'n_estimators': 886, 'max_depth': 7, 'min_child_weight': 2}. Best is trial 19 with value: 0.5588512420654297.
[I 2024-06-30 20:07:17,117] Trial 24 finished with value: 3.75 and parameters: {'lambda': 1.4069575848037913e-05, 'alpha': 0.0037512967705307155, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.04724405137599255, 'n_estimators': 1000, 'max_depth': 7, 'min_child_weight': 4}. Best is trial 19 with value: 0.5588512420654297.
[I 2024-06-30 20:07:17,208] Trial 25 finished with value: 1.033820629119873 and parameters: {'lambda': 0.0022971934126648566, 'alpha': 0.00015650491306438397, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.001476604149894859, 'n_estimators': 873, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 19 with value: 0.5588512420654297.
[I 2024-06-30 20:07:17,280] Trial 26 finished with value: 3.75 and parameters: {'lambda': 0.005184347680222667, 'alpha': 0.008465663127825354, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 9.687984682476273e-05, 'n_estimators': 825, 'max_depth': 5, 'min_child_weight': 3}. Best is trial 19 with value: 0.5588512420654297.
[I 2024-06-30 20:07:17,308] Trial 27 finished with value: 3.75 and parameters: {'lambda': 0.0002838100089500366, 'alpha': 6.545275036669779e-08, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.28484492579198745, 'n_estimators': 223, 'max_depth': 4, 'min_child_weight': 4}. Best is trial 19 with value: 0.5588512420654297.
[I 2024-06-30 20:07:17,397] Trial 28 finished with value: 0.0005578994750976562 and parameters: {'lambda': 1.2972531253099678e-05, 'alpha': 0.0001264609118204621, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.032074002125421774, 'n_estimators': 913, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 28 with value: 0.0005578994750976562.
[I 2024-06-30 20:07:17,465] Trial 29 finished with value: 3.75 and parameters: {'lambda': 1.712294745502461e-05, 'alpha': 0.00017652874160905435, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.07515140908392381, 'n_estimators': 781, 'max_depth': 6, 'min_child_weight': 5}. Best is trial 28 with value: 0.0005578994750976562.
[I 2024-06-30 20:07:17,521] Trial 30 finished with value: 3.75 and parameters: {'lambda': 3.570489656107168e-07, 'alpha': 3.6818506294677225e-06, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.6742031359094061, 'n_estimators': 666, 'max_depth': 6, 'min_child_weight': 3}. Best is trial 28 with value: 0.0005578994750976562.
[I 2024-06-30 20:07:17,628] Trial 31 finished with value: 0.082733154296875 and parameters: {'lambda': 4.923210605556779e-05, 'alpha': 1.515812636524329e-05, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.004159716237963796, 'n_estimators': 915, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 28 with value: 0.0005578994750976562.
[I 2024-06-30 20:07:17,723] Trial 32 finished with value: 0.0005116462707519531 and parameters: {'lambda': 5.109317569912709e-06, 'alpha': 2.5261405231309874e-05, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.01393359749604724, 'n_estimators': 930, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 32 with value: 0.0005116462707519531.
[I 2024-06-30 20:07:17,841] Trial 33 finished with value: 2.9991183280944824 and parameters: {'lambda': 3.7980050612650144e-05, 'alpha': 2.0885497628302264e-05, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.018993826702561636, 'n_estimators': 933, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 32 with value: 0.0005116462707519531.
[I 2024-06-30 20:07:17,935] Trial 34 finished with value: 0.07554149627685547 and parameters: {'lambda': 1.1917357188523283e-07, 'alpha': 5.909832243002859e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.004773943279019122, 'n_estimators': 816, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 32 with value: 0.0005116462707519531.
[I 2024-06-30 20:07:18,005] Trial 35 finished with value: 3.75 and parameters: {'lambda': 1.1335093278937087e-08, 'alpha': 6.781306595727889e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.017810097360861626, 'n_estimators': 783, 'max_depth': 3, 'min_child_weight': 3}. Best is trial 32 with value: 0.0005116462707519531.
[I 2024-06-30 20:07:18,078] Trial 36 finished with value: 3.75 and parameters: {'lambda': 7.123350762265093e-08, 'alpha': 6.221610032706174e-05, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.2031346445514978, 'n_estimators': 804, 'max_depth': 4, 'min_child_weight': 8}. Best is trial 32 with value: 0.0005116462707519531.
[I 2024-06-30 20:07:18,113] Trial 37 finished with value: 3.75 and parameters: {'lambda': 4.011181351821178e-06, 'alpha': 1.8255084066235825e-05, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.00034483304841967214, 'n_estimators': 333, 'max_depth': 4, 'min_child_weight': 5}. Best is trial 32 with value: 0.0005116462707519531.
[I 2024-06-30 20:07:18,279] Trial 38 finished with value: 2.970193862915039 and parameters: {'lambda': 1.9273480140945835e-07, 'alpha': 3.0921010182081318e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.0063075393493200755, 'n_estimators': 857, 'max_depth': 3, 'min_child_weight': 1}. Best is trial 32 with value: 0.0005116462707519531.
[I 2024-06-30 20:07:18,481] Trial 39 finished with value: 0.0005040168762207031 and parameters: {'lambda': 3.9850234489386306e-06, 'alpha': 3.764779153160211e-05, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.03517598993507964, 'n_estimators': 924, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:18,552] Trial 40 finished with value: 3.75 and parameters: {'lambda': 3.555407002279057e-06, 'alpha': 4.472430016551859e-05, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.12080921083219519, 'n_estimators': 564, 'max_depth': 4, 'min_child_weight': 5}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:18,753] Trial 41 finished with value: 0.0006532669067382812 and parameters: {'lambda': 4.55858658841874e-08, 'alpha': 0.0003222448166657141, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.02955417366119222, 'n_estimators': 927, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:18,910] Trial 42 finished with value: 3.75 and parameters: {'lambda': 6.17321612555656e-08, 'alpha': 0.000646299582855558, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.034670596813357026, 'n_estimators': 922, 'max_depth': 5, 'min_child_weight': 3}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:19,036] Trial 43 finished with value: 2.9814629554748535 and parameters: {'lambda': 3.9985281307368256e-08, 'alpha': 0.018055863334394236, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.0183377946509002, 'n_estimators': 957, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:19,111] Trial 44 finished with value: 0.0006451606750488281 and parameters: {'lambda': 6.131809342853728e-07, 'alpha': 0.00032880620980808205, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1555758499124221, 'n_estimators': 762, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:19,191] Trial 45 finished with value: 1.75431489944458 and parameters: {'lambda': 7.623394997511533e-07, 'alpha': 0.00027363347960806, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.6763565255585956, 'n_estimators': 872, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:19,267] Trial 46 finished with value: 3.75 and parameters: {'lambda': 3.4618254703109317e-06, 'alpha': 0.0018387835803954776, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.127974313056927, 'n_estimators': 760, 'max_depth': 5, 'min_child_weight': 4}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:19,330] Trial 47 finished with value: 3.75 and parameters: {'lambda': 5.218316168816377e-07, 'alpha': 9.225251831505347e-05, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.8105522451078342, 'n_estimators': 677, 'max_depth': 5, 'min_child_weight': 7}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:19,435] Trial 48 finished with value: 2.999159097671509 and parameters: {'lambda': 2.1386816940363642e-06, 'alpha': 3.311541770575527e-05, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.029637227955596767, 'n_estimators': 947, 'max_depth': 3, 'min_child_weight': 1}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:19,511] Trial 49 finished with value: 4.042156219482422 and parameters: {'lambda': 6.809478283495943e-06, 'alpha': 0.00034590729132791053, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.07601804903328878, 'n_estimators': 863, 'max_depth': 5, 'min_child_weight': 3}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:19,561] Trial 50 finished with value: 3.75 and parameters: {'lambda': 1.206633916697333e-06, 'alpha': 0.0029471477113332174, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.01138926455301309, 'n_estimators': 479, 'max_depth': 5, 'min_child_weight': 10}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:19,661] Trial 51 finished with value: 0.4385204315185547 and parameters: {'lambda': 1.4297236799312697e-07, 'alpha': 0.00011059167100708435, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.00264612583512498, 'n_estimators': 810, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:19,792] Trial 52 finished with value: 1.6032519340515137 and parameters: {'lambda': 2.699976327755678e-08, 'alpha': 7.79662060637788e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.0005263816781186098, 'n_estimators': 727, 'max_depth': 4, 'min_child_weight': 1}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:19,935] Trial 53 finished with value: 3.6589174270629883 and parameters: {'lambda': 1.993491190804843e-07, 'alpha': 3.845842456223723e-05, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 2.9300888669789487e-05, 'n_estimators': 839, 'max_depth': 4, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,021] Trial 54 finished with value: 4.131101608276367 and parameters: {'lambda': 4.2059456150303906e-07, 'alpha': 0.10667814320722957, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.011474663956243983, 'n_estimators': 902, 'max_depth': 3, 'min_child_weight': 3}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,106] Trial 55 finished with value: 0.0005803108215332031 and parameters: {'lambda': 9.066793867387414e-08, 'alpha': 0.0004048759366410829, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.35480174040493034, 'n_estimators': 979, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,189] Trial 56 finished with value: 2.9988021850585938 and parameters: {'lambda': 7.898591297258518e-06, 'alpha': 0.0004139839747398605, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1933660494017612, 'n_estimators': 966, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,304] Trial 57 finished with value: 0.6468591690063477 and parameters: {'lambda': 2.265852986514735e-08, 'alpha': 9.483652246396178e-05, 'colsample_bytree': 0.3, 'subsample': 0.5, 'learning_rate': 0.3264658515822432, 'n_estimators': 980, 'max_depth': 5, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,329] Trial 58 finished with value: 3.9866943359375 and parameters: {'lambda': 2.3613138047120338e-05, 'alpha': 0.001503905947058699, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.042741031118465854, 'n_estimators': 100, 'max_depth': 5, 'min_child_weight': 3}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,418] Trial 59 finished with value: 2.994633913040161 and parameters: {'lambda': 1.070983506867816e-06, 'alpha': 0.004788918393574173, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.3975271708096484, 'n_estimators': 998, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,503] Trial 60 finished with value: 0.0010328292846679688 and parameters: {'lambda': 2.256670661252063e-06, 'alpha': 0.0010704247408746441, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.09647472004101693, 'n_estimators': 929, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,584] Trial 61 finished with value: 0.0009140968322753906 and parameters: {'lambda': 2.1036319154424675e-06, 'alpha': 0.0008914575262766493, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.11583394319069264, 'n_estimators': 924, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,662] Trial 62 finished with value: 3.75 and parameters: {'lambda': 7.753895088523596e-06, 'alpha': 0.00042325755097732547, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1617190973792913, 'n_estimators': 892, 'max_depth': 7, 'min_child_weight': 3}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,776] Trial 63 finished with value: 3.75 and parameters: {'lambda': 3.0395003101424754e-07, 'alpha': 0.00017744253910654178, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 1.7152286791108195e-08, 'n_estimators': 945, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,856] Trial 64 finished with value: 0.4600257873535156 and parameters: {'lambda': 6.896305611774066e-07, 'alpha': 0.9190836088504529, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.05639858157604492, 'n_estimators': 857, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:20,938] Trial 65 finished with value: 0.2286362648010254 and parameters: {'lambda': 8.582696465108272e-08, 'alpha': 7.096050407655897e-05, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.42908888290257746, 'n_estimators': 976, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:21,014] Trial 66 finished with value: 3.75 and parameters: {'lambda': 1.7261918494259393e-06, 'alpha': 0.0005992410368211362, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.0282189471944611, 'n_estimators': 890, 'max_depth': 5, 'min_child_weight': 9}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:21,093] Trial 67 finished with value: 3.75 and parameters: {'lambda': 2.85679296753196e-05, 'alpha': 0.011800474221341267, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.009448439805086684, 'n_estimators': 918, 'max_depth': 7, 'min_child_weight': 4}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:21,180] Trial 68 finished with value: 3.75 and parameters: {'lambda': 0.0001155835577082339, 'alpha': 0.0026578108759842426, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.0023546510840382856, 'n_estimators': 999, 'max_depth': 6, 'min_child_weight': 3}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:21,254] Trial 69 finished with value: 2.9989988803863525 and parameters: {'lambda': 6.665064566077947e-06, 'alpha': 0.00017519644025781783, 'colsample_bytree': 0.7, 'subsample': 1.0, 'learning_rate': 0.07576157172865187, 'n_estimators': 770, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:21,336] Trial 70 finished with value: 2.9993317127227783 and parameters: {'lambda': 4.1406031390214414e-08, 'alpha': 2.7185143174491687e-05, 'colsample_bytree': 0.3, 'subsample': 0.9, 'learning_rate': 0.20289284074099367, 'n_estimators': 951, 'max_depth': 5, 'min_child_weight': 1}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:21,424] Trial 71 finished with value: 0.000995635986328125 and parameters: {'lambda': 2.4524947421459057e-06, 'alpha': 0.0009949995947418615, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.0853787333979046, 'n_estimators': 916, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:21,508] Trial 72 finished with value: 0.0009336471557617188 and parameters: {'lambda': 1.3225117513813596e-05, 'alpha': 0.000871592425809227, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.04637187646298333, 'n_estimators': 841, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:21,589] Trial 73 finished with value: 4.235710144042969 and parameters: {'lambda': 1.2953152224397317e-05, 'alpha': 0.00029069202891741203, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.024967797720734798, 'n_estimators': 841, 'max_depth': 6, 'min_child_weight': 3}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:21,670] Trial 74 finished with value: 0.0032758712768554688 and parameters: {'lambda': 4.798802303869883e-06, 'alpha': 0.005580200613029539, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.04376989034923755, 'n_estimators': 793, 'max_depth': 6, 'min_child_weight': 2}. Best is trial 39 with value: 0.0005040168762207031.
[I 2024-06-30 20:07:21,743] Trial 75 finished with value: 0.00016164779663085938 and parameters: {'lambda': 1.2917506091380822e-05, 'alpha': 1.2975040351002447e-05, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.9197903192195737, 'n_estimators': 879, 'max_depth': 7, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:21,822] Trial 76 finished with value: 2.9993696212768555 and parameters: {'lambda': 6.617821676792246e-05, 'alpha': 6.0883106937251656e-05, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.35270388049129836, 'n_estimators': 886, 'max_depth': 8, 'min_child_weight': 1}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:21,898] Trial 77 finished with value: 3.75 and parameters: {'lambda': 2.578212774564079e-07, 'alpha': 1.388930468070321e-05, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.9741332149193304, 'n_estimators': 939, 'max_depth': 8, 'min_child_weight': 3}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:21,985] Trial 78 finished with value: 0.21748685836791992 and parameters: {'lambda': 6.039716267296792e-07, 'alpha': 1.0219338099157258e-05, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.5298386326379165, 'n_estimators': 976, 'max_depth': 7, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,048] Trial 79 finished with value: 0.0004038810729980469 and parameters: {'lambda': 0.00019935177931284801, 'alpha': 2.150097773889471e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.24847469886808407, 'n_estimators': 703, 'max_depth': 7, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,113] Trial 80 finished with value: 3.75 and parameters: {'lambda': 0.00020791713752647402, 'alpha': 3.6145797390625068e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.26006947444353545, 'n_estimators': 707, 'max_depth': 7, 'min_child_weight': 6}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,187] Trial 81 finished with value: 0.0004801750183105469 and parameters: {'lambda': 0.0006265767326847105, 'alpha': 1.2643528537222532e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.1235575915558501, 'n_estimators': 899, 'max_depth': 7, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,270] Trial 82 finished with value: 0.0002231597900390625 and parameters: {'lambda': 0.000531599233377414, 'alpha': 1.8758337914392168e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.5873529669833906, 'n_estimators': 610, 'max_depth': 8, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,335] Trial 83 finished with value: 2.9998745918273926 and parameters: {'lambda': 0.0007572081314591767, 'alpha': 3.7909850439875475e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.6974346064275144, 'n_estimators': 619, 'max_depth': 9, 'min_child_weight': 1}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,397] Trial 84 finished with value: 3.75 and parameters: {'lambda': 0.00022629663258185099, 'alpha': 1.5129577909668927e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.15458877071652255, 'n_estimators': 651, 'max_depth': 8, 'min_child_weight': 3}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,458] Trial 85 finished with value: 0.00025272369384765625 and parameters: {'lambda': 0.001982750718787987, 'alpha': 5.421749103157277e-07, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.522874667980956, 'n_estimators': 598, 'max_depth': 8, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,523] Trial 86 finished with value: 1.4821500778198242 and parameters: {'lambda': 0.002730054775575234, 'alpha': 3.421887827683387e-07, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.5471524191674251, 'n_estimators': 597, 'max_depth': 8, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,580] Trial 87 finished with value: 2.9998297691345215 and parameters: {'lambda': 0.0011472159578787059, 'alpha': 6.47028708018356e-08, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.9302407187994362, 'n_estimators': 561, 'max_depth': 8, 'min_child_weight': 1}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,632] Trial 88 finished with value: 3.428731918334961 and parameters: {'lambda': 0.015647620785427644, 'alpha': 4.961248297690016e-07, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.2540288066018987, 'n_estimators': 498, 'max_depth': 9, 'min_child_weight': 3}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,707] Trial 89 finished with value: 3.75 and parameters: {'lambda': 0.006584118772432663, 'alpha': 1.5280736794024893e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 5.204425499115026e-08, 'n_estimators': 523, 'max_depth': 7, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,772] Trial 90 finished with value: 2.9993529319763184 and parameters: {'lambda': 0.00042428204070143723, 'alpha': 1.6433653124896682e-07, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.48382690747923235, 'n_estimators': 647, 'max_depth': 7, 'min_child_weight': 1}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,834] Trial 91 finished with value: 0.00044345855712890625 and parameters: {'lambda': 0.0006901805914439161, 'alpha': 9.006873940915027e-07, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.12994453083561872, 'n_estimators': 587, 'max_depth': 8, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,895] Trial 92 finished with value: 0.0004763603210449219 and parameters: {'lambda': 0.0008423242151757331, 'alpha': 8.100591180915401e-07, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.2919452176971695, 'n_estimators': 602, 'max_depth': 8, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:22,949] Trial 93 finished with value: 0.0003981590270996094 and parameters: {'lambda': 0.0008307061297317719, 'alpha': 9.377122022319644e-07, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.24229609439639327, 'n_estimators': 592, 'max_depth': 8, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:23,011] Trial 94 finished with value: 0.000385284423828125 and parameters: {'lambda': 0.0014288518320848772, 'alpha': 8.659704135320748e-07, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.2496801410742194, 'n_estimators': 591, 'max_depth': 8, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:23,076] Trial 95 finished with value: 3.75 and parameters: {'lambda': 0.0014698586765229823, 'alpha': 6.974462066813908e-07, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.24042488892854696, 'n_estimators': 586, 'max_depth': 8, 'min_child_weight': 3}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:23,133] Trial 96 finished with value: 0.00026416778564453125 and parameters: {'lambda': 0.003549962719716885, 'alpha': 2.140200875672299e-06, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.5818910345982816, 'n_estimators': 528, 'max_depth': 8, 'min_child_weight': 2}. Best is trial 75 with value: 0.00016164779663085938.
[I 2024-06-30 20:07:23,189] Trial 97 finished with value: 0.00013589859008789062 and parameters: {'lambda': 0.0036432712890952885, 'alpha': 8.607596289842398e-07, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.9686860105270193, 'n_estimators': 531, 'max_depth': 8, 'min_child_weight': 2}. Best is trial 97 with value: 0.00013589859008789062.
[I 2024-06-30 20:07:23,242] Trial 98 finished with value: 3.7222375869750977 and parameters: {'lambda': 0.003927940108986055, 'alpha': 2.5260430430728245e-06, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.6373222896888983, 'n_estimators': 532, 'max_depth': 8, 'min_child_weight': 3}. Best is trial 97 with value: 0.00013589859008789062.
[I 2024-06-30 20:07:23,308] Trial 99 finished with value: 0.4771690368652344 and parameters: {'lambda': 0.0009254984134372111, 'alpha': 4.240329598205621e-07, 'colsample_bytree': 0.5, 'subsample': 0.9, 'learning_rate': 0.9541417063082294, 'n_estimators': 579, 'max_depth': 9, 'min_child_weight': 2}. Best is trial 97 with value: 0.00013589859008789062.
=============================== warnings summary ===============================
../../../../anaconda3/lib/python3.11/site-packages/plotly/express/imshow_utils.py:24
  /Users/carlopiccinin/anaconda3/lib/python3.11/site-packages/plotly/express/imshow_utils.py:24: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
    np.bool8: (False, True),

tests/test_diamond_model.py::test_get_similar_samples
  /Users/carlopiccinin/Desktop/side projects/xtream-ai/xtream-ai-assignment-developer/DiamondModels.py:884: SettingWithCopyWarning: 
  A value is trying to be set on a copy of a slice from a DataFrame.
  Try using .loc[row_indexer,col_indexer] = value instead
  
  See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    filtered_data['weight_diff'] = (filtered_data['carat'] - carat).abs()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/test_MLP_model.py::test_mlp_get_params - TypeError: 'NoneType' o...
FAILED tests/test_MLP_model.py::test_mlp_save_load - RuntimeError: Error(s) i...
FAILED tests/test_diamond_model.py::test_get_similar_samples - assert 1 == 2
FAILED tests/test_diamond_model.py::test_prepare_data_for_prediction - ValueE...
FAILED tests/test_diamond_model.py::test_different_models[MLP] - RuntimeError...
FAILED tests/test_xgb_regressor_model.py::test_xgb_regressor_predict - Assert...
FAILED tests/test_xgb_regressor_model.py::test_xgb_regressor_get_params - Att...
============= 7 failed, 32 passed, 2 warnings in 74.55s (0:01:14) ==============
